{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from ase.units import create_units\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql import Row\n",
    "import itertools\n",
    "from ast import literal_eval\n",
    "from pyspark.sql.types import StructField, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MD/1989/MD_1206814276940281681221989.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trim_prefix(metadata_path):\n",
    "    if metadata_path is None:\n",
    "        return None\n",
    "    if metadata_path.startswith(\"/vdev/colabfit-data/MD\"):\n",
    "        return metadata_path.replace(\"/vdev/colabfit-data\", \"data\")\n",
    "    elif metadata_path.startswith(\"/vdev/colabfit-data/data\"):\n",
    "        return metadata_path.replace(\"/vdev/colabfit-data/data\", \"data\")\n",
    "    else:\n",
    "        return metadata_path\n",
    "\n",
    "\n",
    "trim_prefix(\"/vdev/colabfit-data/MD/1989/MD_1206814276940281681221989.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/MD/9668/MD_8737377704434833080489668.json'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_prefix(\"/vdev/colabfit-data/data/MD/9668/MD_8737377704434833080489668.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_prefix(metadata_path):\n",
    "    if metadata_path is None:\n",
    "        return None\n",
    "    if metadata_path.startswith(\"/vdev/colabfit-data/MD\"):\n",
    "        return metadata_path.replace(\"/vdev/colabfit-data\", \"data\")\n",
    "    elif metadata_path.startswith(\"/vdev/colabfit-data/data\"):\n",
    "        return metadata_path.replace(\"/vdev/colabfit-data/data\", \"data\")\n",
    "\n",
    "    return metadata_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNITS = create_units(\"2014\")\n",
    "\n",
    "UNITS[\"angstrom\"] = UNITS[\"Ang\"]\n",
    "UNITS[\"bohr\"] = UNITS[\"Bohr\"]\n",
    "UNITS[\"hartree\"] = UNITS[\"Hartree\"]\n",
    "UNITS[\"rydberg\"] = UNITS[\"Rydberg\"]\n",
    "UNITS[\"debye\"] = UNITS[\"Debye\"]\n",
    "UNITS[\"kbar\"] = UNITS[\"bar\"] * 1000\n",
    "\n",
    "\n",
    "prop_info = namedtuple(\"prop_info\", [\"unit\", \"dtype\"])\n",
    "energy_info = prop_info([\"eV\"], float)\n",
    "force_info = prop_info([\"eV/angstrom\", \"eV/angstrom^3\"], list)\n",
    "stress_info = prop_info([\"eV/angstrom^3\"], list)\n",
    "MAIN_KEY_MAP = {\n",
    "    \"potential_energy\": energy_info,\n",
    "    \"atomic_forces_00\": force_info,\n",
    "    \"cauchy_stress\": stress_info,\n",
    "    \"atomization_energy\": energy_info,\n",
    "    \"formation_energy\": energy_info,\n",
    "    \"band_gap\": energy_info,\n",
    "    \"free_energy\": energy_info,\n",
    "}\n",
    "\n",
    "\n",
    "def standardize_energy(row: Row):\n",
    "    \"\"\"\n",
    "    For each key in :attr:`self.property_map`, convert :attr:`self.edn[key]`\n",
    "    from its original units to the expected ColabFit-compliant units.\n",
    "    \"\"\"\n",
    "    rowdict = row.asDict()\n",
    "    for prop_name, val in rowdict.items():\n",
    "        if prop_name not in MAIN_KEY_MAP.keys():\n",
    "            continue\n",
    "        if val is None:\n",
    "            continue\n",
    "        p_info = MAIN_KEY_MAP[prop_name]\n",
    "        unit_col = f\"{prop_name}_unit\"\n",
    "        if prop_name[-2:] == \"00\":\n",
    "            unit_col = f\"{prop_name[:-3]}_unit\"\n",
    "        units = rowdict[unit_col]\n",
    "        if p_info.dtype == list:\n",
    "            val = literal_eval(val)\n",
    "            prop_val = np.array(val, dtype=np.float64)\n",
    "        else:\n",
    "            prop_val = val\n",
    "        ref_en_col = f\"{prop_name}_reference\"\n",
    "        if ref_en_col in rowdict and rowdict[ref_en_col] is not None:\n",
    "            if rowdict[f\"{ref_en_col}_unit\"] != units:\n",
    "                raise RuntimeError(\n",
    "                    \"Units of the reference energy and energy must be the same\"\n",
    "                )\n",
    "            else:\n",
    "                prop_val += rowdict[ref_en_col]\n",
    "        per_atom_col = f\"{prop_name}_per_atom\"\n",
    "        if per_atom_col in rowdict:\n",
    "            if rowdict[per_atom_col] is True:\n",
    "                if rowdict[\"nsites\"] is None:\n",
    "                    raise RuntimeError(\"nsites must be provided to convert per-atom\")\n",
    "                prop_val *= rowdict[\"nsites\"]\n",
    "        if units not in p_info.unit:\n",
    "            split_units = list(\n",
    "                itertools.chain.from_iterable(\n",
    "                    [\n",
    "                        sp.split(\"^\")\n",
    "                        for sp in itertools.chain.from_iterable(\n",
    "                            [sp.split(\"/\") for sp in units.split(\"*\")]\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            prop_val *= float(UNITS[split_units[0]])\n",
    "            for u in split_units[1:]:\n",
    "                if units[units.find(u) - 1] == \"*\":\n",
    "                    prop_val *= UNITS[u]\n",
    "                elif units[units.find(u) - 1] == \"/\":\n",
    "                    prop_val /= UNITS[u]\n",
    "                elif units[units.find(u) - 1] == \"^\":\n",
    "                    try:\n",
    "                        prop_val = np.power(prop_val, int(u))\n",
    "                    except Exception:\n",
    "                        raise RuntimeError(\n",
    "                            f\"There may be something wrong with the units: {u}\"\n",
    "                        )\n",
    "                else:\n",
    "                    raise RuntimeError(\n",
    "                        f\"There may be something wrong with the units: {u}\"\n",
    "                    )\n",
    "        if p_info.dtype == list:\n",
    "            prop_val = prop_val.tolist()\n",
    "        rowdict[prop_name] = prop_val\n",
    "        rowdict[unit_col] = p_info.unit[0]\n",
    "    return Row(**rowdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, ArrayType\n",
    "import numpy as np\n",
    "import itertools\n",
    "from ast import literal_eval\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "\n",
    "@sf.udf(returnType=DoubleType())\n",
    "def standardize_energy_udf(en_col, unit_col):\n",
    "    val = en_col\n",
    "    if val is None:\n",
    "        return None\n",
    "    units = unit_col\n",
    "    prop_val = val\n",
    "    if units != \"eV\":\n",
    "        split_units = list(\n",
    "            itertools.chain.from_iterable(\n",
    "                [\n",
    "                    sp.split(\"^\")\n",
    "                    for sp in itertools.chain.from_iterable(\n",
    "                        [sp.split(\"/\") for sp in units.split(\"*\")]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        prop_val *= float(UNITS[split_units[0]])\n",
    "        for u in split_units[1:]:\n",
    "            if units[units.find(u) - 1] == \"*\":\n",
    "                prop_val *= UNITS[u]\n",
    "            elif units[units.find(u) - 1] == \"/\":\n",
    "                prop_val /= UNITS[u]\n",
    "            elif units[units.find(u) - 1] == \"^\":\n",
    "                try:\n",
    "                    prop_val = np.power(prop_val, int(u))\n",
    "                except Exception:\n",
    "                    raise RuntimeError(\n",
    "                        f\"There may be something wrong with the units: {u}\"\n",
    "                    )\n",
    "            else:\n",
    "                raise RuntimeError(f\"There may be something wrong with the units: {u}\")\n",
    "    return prop_val\n",
    "\n",
    "\n",
    "@sf.udf(returnType=ArrayType(ArrayType(DoubleType())))\n",
    "def standardize_array_udf(af_col, unit_col, unit):\n",
    "    val = af_col\n",
    "    if val is None or val == \"[]\":\n",
    "        return \"[]\"\n",
    "    units = unit_col\n",
    "    prop_val = val\n",
    "    val = literal_eval(val)\n",
    "    prop_val = np.array(val, dtype=np.float64)\n",
    "    if units not in unit:\n",
    "        split_units = list(\n",
    "            itertools.chain.from_iterable(\n",
    "                [\n",
    "                    sp.split(\"^\")\n",
    "                    for sp in itertools.chain.from_iterable(\n",
    "                        [sp.split(\"/\") for sp in units.split(\"*\")]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        prop_val *= float(UNITS[split_units[0]])\n",
    "        for u in split_units[1:]:\n",
    "            if units[units.find(u) - 1] == \"*\":\n",
    "                prop_val *= UNITS[u]\n",
    "            elif units[units.find(u) - 1] == \"/\":\n",
    "                prop_val /= UNITS[u]\n",
    "            elif units[units.find(u) - 1] == \"^\":\n",
    "                try:\n",
    "                    prop_val = np.power(prop_val, int(u))\n",
    "                except Exception:\n",
    "                    raise RuntimeError(\n",
    "                        f\"There may be something wrong with the units: {u}\"\n",
    "                    )\n",
    "            else:\n",
    "                raise RuntimeError(f\"There may be something wrong with the units: {u}\")\n",
    "    prop_val = prop_val.tolist()\n",
    "    print(prop_val)\n",
    "    return prop_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "\n",
    "pos = spark.table(\"ndb.colabfit.dev.pos_convert_v3\")\n",
    "\n",
    "po_forces = (\n",
    "    pos.filter(sf.col(\"atomic_forces_unit\") != \"eV/angstrom\")\n",
    "    .filter(sf.col(\"atomic_forces_unit\") != \"eV/angstrom^3\")\n",
    "    .limit(100)\n",
    ")\n",
    "\n",
    "for col in [\n",
    "    \"potential_energy\",\n",
    "    \"free_energy\",\n",
    "    \"electronic_band_gap\",\n",
    "    \"adsorption_energy\",\n",
    "    \"atomization_energy\",\n",
    "    \"formation_energy\",\n",
    "]:\n",
    "    po_forces3 = po_forces.withColumn(\n",
    "        col,\n",
    "        standardize_energy_udf(sf.col(col), sf.col(f\"{col}_unit\")),\n",
    "    )\n",
    "\n",
    "po_forces3 = po_forces.withColumn(\n",
    "    \"atomic_forces_00\",\n",
    "    standardize_array_udf(\n",
    "        sf.col(\"atomic_forces_00\"),\n",
    "        sf.col(\"atomic_forces_unit\"),\n",
    "        sf.lit(force_info.unit),\n",
    "    ),\n",
    ")\n",
    "\n",
    "po_forces3 = po_forces3.withColumn(\n",
    "    \"cauchy_stress\",\n",
    "    standardize_array_udf(\n",
    "        sf.col(\"cauchy_stress\"), sf.col(\"cauchy_stress_unit\"), sf.lit(stress_info.unit)\n",
    "    ),\n",
    ")\n",
    "\n",
    "po_forces3.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = spark.table(\"ndb.colabfit.dev.pos_convert_v3\")\n",
    "\n",
    "co_nsites = (\n",
    "    spark.table(\"ndb.colabfit.dev.co_convert\")\n",
    "    .select(\"id\", \"nsites\")\n",
    "    .withColumnRenamed(\"id\", \"configuration_id\")\n",
    ").limit(100)\n",
    "\n",
    "po_sites = pos.join(co_nsites, on=\"configuration_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sf.udf(\"float\")\n",
    "def convert_energy(val, unit):\n",
    "    if unit != ref_unit:\n",
    "        raise RuntimeError(\"Units of the reference energy and energy must be the same\")\n",
    "    return val\n",
    "\n",
    "\n",
    "df = spark.table(\"ndb.colabfit.dev.pos_convert\")\n",
    "unit = \"eV/angstrom\"\n",
    "unit_col = \"atomic_forces_unit\"\n",
    "col = \"atomic_forces_00\"\n",
    "df = df.withColumn(\n",
    "    col,\n",
    "    sf.when(\n",
    "        sf.col(unit_col) != unit,\n",
    "        convert_energy(\n",
    "            col,\n",
    "            unit_col,\n",
    "        ),\n",
    "    ).otherwise(sf.col(col)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "def alter_schema(row: Row):\n",
    "    rowdict = row.asDict()\n",
    "    if rowdict[\"free_energy\"] is not None:\n",
    "        rowdict[\"target_energy\"] = rowdict[\"free_energy\"]\n",
    "    elif rowdict[\"potential_energy\"] is not None:\n",
    "        rowdict[\"target_energy\"] = rowdict[\"potential_energy\"]\n",
    "    else:\n",
    "        rowdict[\"target_energy\"] = None\n",
    "    return Row(**rowdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targen_schema = po_forces2.schema\n",
    "targen_schema.add(StructField(\"target_energy\", FloatType(), True))\n",
    "\n",
    "\n",
    "po_targen = po_forces2.rdd.map(alter_schema).toDF(schema=targen_schema)\n",
    "po_targen2 = po_targen.select(\n",
    "    [\n",
    "        c\n",
    "        for c in po_targen.columns\n",
    "        if (\n",
    "            \"unit\" not in c\n",
    "            and \"property_id\" not in c\n",
    "            and \"reference\" not in c\n",
    "            and \"potential_energy\" not in c\n",
    "            and \"free_energy\" not in c\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "po_targen2.first()\n",
    "po_targen2.join(\n",
    "    co_nsites, po_targen2.configuration_id == co_nsites.configuration_id, how=\"inner\"\n",
    ").first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
